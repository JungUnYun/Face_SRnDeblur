{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SRnDeblur_joint 1104 test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.backends import cudnn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, batch_size):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        bn = None\n",
    "        if batch_size == 1:\n",
    "            bn = False # Instance Normalization\n",
    "        else:\n",
    "            bn = True # Batch Normalization\n",
    "\n",
    "        #============================ upscale ============================#\n",
    "        self.upscale8 = nn.Sequential(\n",
    "            # [3x32x32] -> [64x32x32]\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=9, stride=1, padding=4, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # [64x32x32] -> [256x32x32]\n",
    "            nn.Conv2d(in_channels=64, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            # [256x32x32] -> [64x64x64]\n",
    "            nn.PixelShuffle(2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # [64x64x64] -> [256x64x64]\n",
    "            nn.Conv2d(in_channels=64, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            # [256x64x64] -> [64x128x128]\n",
    "            nn.PixelShuffle(2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # [64x128x128] -> [256x128x128]\n",
    "            nn.Conv2d(in_channels=64, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            # [256x128x128] -> [64x256x256]\n",
    "            nn.PixelShuffle(2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),  \n",
    "            # [64x256x256] -> [3x256x256]\n",
    "            nn.Conv2d(in_channels=64, out_channels=3, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        )\n",
    "        #============================ upscale ============================#\n",
    "\n",
    "\n",
    "        # nn.Conv2d(input channel 수, convolution에 의해 생성된 channel 수, kernel size, stride=default 1, padding=default 0)\n",
    "        # [3x256x256] -> [64x128x128]\n",
    "        self.conv1 = nn.Conv2d(3, 64, 4, 2, 1)\n",
    "        # [64x256x256] -> [64x128x128]\n",
    "#         self.conv1 = nn.Conv2d(64, 64, 3, 1, 1)\n",
    "\n",
    "        # -> [128x64x64]\n",
    "        conv2 = [nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            conv2 += [nn.BatchNorm2d(128)]\n",
    "        else:\n",
    "            conv2 += [nn.InstanceNorm2d(128)]\n",
    "        self.conv2 = nn.Sequential(*conv2)\n",
    "\n",
    "        # -> [256x32x32]\n",
    "        conv3 = [nn.LeakyReLU(0.2, inplace=True),\n",
    "                 nn.Conv2d(128, 256, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            conv3 += [nn.BatchNorm2d(256)]\n",
    "        else:\n",
    "            conv3 += [nn.InstanceNorm2d(256)]\n",
    "        self.conv3 = nn.Sequential(*conv3)\n",
    "\n",
    "        # -> [512x16x16]\n",
    "        conv4 = [nn.LeakyReLU(0.2, inplace=True),\n",
    "                 nn.Conv2d(256, 512, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            conv4 += [nn.BatchNorm2d(512)]\n",
    "        else:\n",
    "            conv4 += [nn.InstanceNorm2d(512)]\n",
    "        self.conv4 = nn.Sequential(*conv4)\n",
    "\n",
    "        # -> [512x8x8]\n",
    "        conv5 = [nn.LeakyReLU(0.2, inplace=True),\n",
    "                 nn.Conv2d(512, 512, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            conv5 += [nn.BatchNorm2d(512)]\n",
    "        else:\n",
    "            conv5 += [nn.InstanceNorm2d(512)]\n",
    "        self.conv5 = nn.Sequential(*conv5)\n",
    "\n",
    "        # -> [512x4x4]\n",
    "        conv6 = [nn.LeakyReLU(0.2, inplace=True),\n",
    "                 nn.Conv2d(512, 512, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            conv6 += [nn.BatchNorm2d(512)]\n",
    "        else:\n",
    "            conv6 += [nn.InstanceNorm2d(512)]\n",
    "        self.conv6 = nn.Sequential(*conv6)\n",
    "\n",
    "        # -> [512x2x2]\n",
    "        conv7 = [nn.LeakyReLU(0.2, inplace=True),\n",
    "                 nn.Conv2d(512, 512, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            conv7 += [nn.BatchNorm2d(512)]\n",
    "        else:\n",
    "            conv7 += [nn.InstanceNorm2d(512)]\n",
    "        self.conv7 = nn.Sequential(*conv7)\n",
    "\n",
    "        # -> [512x1x1]\n",
    "        conv8 = [nn.LeakyReLU(0.2, inplace=True),\n",
    "                 nn.Conv2d(512, 512, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            conv8 += [nn.BatchNorm2d(512)]\n",
    "        else:\n",
    "            conv8 += [nn.InstanceNorm2d(512)]\n",
    "        self.conv8 = nn.Sequential(*conv8)\n",
    "\n",
    "        # -> [512x2x2]\n",
    "        deconv8 = [nn.ReLU(),\n",
    "                   nn.ConvTranspose2d(512, 512, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            deconv8 += [nn.BatchNorm2d(512), nn.Dropout(0.5)]\n",
    "        else:\n",
    "            deconv8 += [nn.InstanceNorm2d(512), nn.Dropout(0.5)]\n",
    "        self.deconv8 = nn.Sequential(*deconv8)\n",
    "\n",
    "        # [(512+512)x2x2] -> [512x4x4]\n",
    "        deconv7 = [nn.ReLU(),\n",
    "                   nn.ConvTranspose2d(512 * 2, 512, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            deconv7 += [nn.BatchNorm2d(512), nn.Dropout(0.5)]\n",
    "        else:\n",
    "            deconv7 += [nn.InstanceNorm2d(512), nn.Dropout(0.5)]\n",
    "        self.deconv7 = nn.Sequential(*deconv7)\n",
    "\n",
    "        # [(512+512)x4x4] -> [512x8x8]\n",
    "        deconv6 = [nn.ReLU(),\n",
    "                   nn.ConvTranspose2d(512 * 2, 512, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            deconv6 += [nn.BatchNorm2d(512), nn.Dropout(0.5)]\n",
    "        else:\n",
    "            deconv6 += [nn.InstanceNorm2d(512), nn.Dropout(0.5)]\n",
    "        self.deconv6 = nn.Sequential(*deconv6)\n",
    "\n",
    "        # [(512+512)x8x8] -> [512x16x16]\n",
    "        deconv5 = [nn.ReLU(),\n",
    "                   nn.ConvTranspose2d(512 * 2, 512, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            deconv5 += [nn.BatchNorm2d(512)]\n",
    "        else:\n",
    "            deconv5 += [nn.InstanceNorm2d(512)]\n",
    "        self.deconv5 = nn.Sequential(*deconv5)\n",
    "\n",
    "        # [(512+512)x16x16] -> [256x32x32]\n",
    "        deconv4 = [nn.ReLU(),\n",
    "                   nn.ConvTranspose2d(512 * 2, 256, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            deconv4 += [nn.BatchNorm2d(256)]\n",
    "        else:\n",
    "            deconv4 += [nn.InstanceNorm2d(256)]\n",
    "        self.deconv4 = nn.Sequential(*deconv4)\n",
    "        \n",
    "        # [(512+512)x16x16] -> [256x32x32]\n",
    "        deconv4_0 = [nn.ReLU(),\n",
    "                   nn.ConvTranspose2d(512 * 1, 256, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            deconv4_0 += [nn.BatchNorm2d(256)]\n",
    "        else:\n",
    "            deconv4_0 += [nn.InstanceNorm2d(256)]\n",
    "        self.deconv4_0 = nn.Sequential(*deconv4_0)        \n",
    "\n",
    "        # [(256+256)x32x32] -> [128x64x64]\n",
    "        deconv3 = [nn.ReLU(),\n",
    "                   nn.ConvTranspose2d(256 * 2, 128, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            deconv3 += [nn.BatchNorm2d(128)]\n",
    "        else:\n",
    "            deconv3 += [nn.InstanceNorm2d(128)]\n",
    "        self.deconv3 = nn.Sequential(*deconv3)\n",
    "\n",
    "        # [(256+256)x32x32] -> [128x64x64]\n",
    "        deconv3_0 = [nn.ReLU(),\n",
    "                   nn.ConvTranspose2d(256 * 2, 128, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            deconv3_0 += [nn.BatchNorm2d(128)]\n",
    "        else:\n",
    "            deconv3_0 += [nn.InstanceNorm2d(128)]\n",
    "        self.deconv3_0 = nn.Sequential(*deconv3_0)\n",
    "        \n",
    "        # [(128+128)x64x64] -> [64x128x128]\n",
    "        deconv2 = [nn.ReLU(),\n",
    "                   nn.ConvTranspose2d(128 * 2, 64, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            deconv2 += [nn.BatchNorm2d(64)]\n",
    "        else:\n",
    "            deconv2 += [nn.InstanceNorm2d(64)]\n",
    "        self.deconv2 = nn.Sequential(*deconv2)\n",
    "        \n",
    "        # [(128+128)x64x64] -> [64x128x128]\n",
    "        deconv2_0 = [nn.ReLU(),\n",
    "                   nn.ConvTranspose2d(128 * 2, 64, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            deconv2_0 += [nn.BatchNorm2d(64)]\n",
    "        else:\n",
    "            deconv2_0 += [nn.InstanceNorm2d(64)]\n",
    "        self.deconv2_0 = nn.Sequential(*deconv2_0)\n",
    "\n",
    "        # [(64+64)x128x128] -> [3x256x256]\n",
    "        self.deconv1 = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64 * 2, 3, 4, 2, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        # [(64+64)x128x128] -> [3x256x256]\n",
    "        self.deconv1_0 = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64 * 2, 3, 4, 2, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # NCHW = H*W\n",
    "        \n",
    "        noise = torch.empty_like(x).normal_(mean=1.0,std=0.1)\n",
    "        inN = x + noise\n",
    "        upx = self.upscale8(inN)\n",
    "        \n",
    "        c1 = self.conv1(upx)\n",
    "        c1_1 = torch.empty_like(c1).normal_(mean=1.0,std=0.1)\n",
    "        c1_n = c1 + c1_1\n",
    "        c2 = self.conv2(c1_n)\n",
    "        c2_1 = torch.empty_like(c2).normal_(mean=1.0,std=0.1)\n",
    "        c2_n = c2 + c2_1\n",
    "        c3 = self.conv3(c2_n)\n",
    "        c3_1 = torch.empty_like(c3).normal_(mean=1.0,std=0.1)\n",
    "        c3_n = c3 + c3_1\n",
    "        c4 = self.conv4(c3_n)\n",
    "        c4_1 = torch.empty_like(c4).normal_(mean=1.0,std=0.1)\n",
    "        c4_n = c4 + c4_1\n",
    "        c5 = self.conv5(c4_n)\n",
    "        c5_1 = torch.empty_like(c5).normal_(mean=1.0,std=0.1)\n",
    "        c5_n = c5 + c5_1\n",
    "        c6 = self.conv6(c5_n)\n",
    "        c6_1 = torch.empty_like(c6).normal_(mean=1.0,std=0.1)\n",
    "        c6_n = c6 + c6_1\n",
    "        c7 = self.conv7(c6_n)\n",
    "        c7_1 = torch.empty_like(c7).normal_(mean=1.0,std=0.1)\n",
    "        c7_n = c7 + c7_1\n",
    "        c8 = self.conv8(c7_n)\n",
    "        c8_1 = torch.empty_like(c8).normal_(mean=1.0,std=0.1)\n",
    "        c8_n = c8 + c8_1\n",
    "        \n",
    "        d3_0 = self.deconv4_0(c4_n)\n",
    "        d3_0 = torch.cat((c3,d3_0), dim=1)\n",
    "        d3_1 = torch.empty_like(d3_0).normal_(mean=1.0,std=0.1)\n",
    "        d3_n = d3_0 + d3_1\n",
    "        d2_0 = self.deconv3_0(d3_n)\n",
    "        d2_0 = torch.cat((c2,d2_0), dim=1)\n",
    "        d2_1 = torch.empty_like(d2_0).normal_(mean=1.0,std=0.1)\n",
    "        d2_n = d2_0 + d2_1\n",
    "        d1_0 = self.deconv2_0(d2_n)\n",
    "        d1_00 = torch.cat((c1,d1_0), dim=1)    \n",
    "        d1_1 = torch.empty_like(d1_00).normal_(mean=1.0,std=0.1)\n",
    "        d1_n = d1_00 + d1_1\n",
    "        outLR = self.deconv1_0(d1_n)\n",
    "        \n",
    "        d7 = self.deconv8(c8_n)\n",
    "        d7 = torch.cat((c7, d7), dim=1)\n",
    "        d17_1 = torch.empty_like(d7).normal_(mean=1.0,std=0.1)\n",
    "        d17_n = d7 + d17_1\n",
    "        d6 = self.deconv7(d17_n)\n",
    "        d6 = torch.cat((c6, d6), dim=1)\n",
    "        d16_1 = torch.empty_like(d6).normal_(mean=1.0,std=0.1)\n",
    "        d16_n = d6 + d16_1\n",
    "        d5 = self.deconv6(d16_n)\n",
    "        d5 = torch.cat((c5, d5), dim=1)\n",
    "        d15_1 = torch.empty_like(d5).normal_(mean=1.0,std=0.1)\n",
    "        d15_n = d5 + d15_1\n",
    "        d4 = self.deconv5(d15_n)\n",
    "        d4 = torch.cat((c4, d4), dim=1)\n",
    "        d14_1 = torch.empty_like(d4).normal_(mean=1.0,std=0.1)\n",
    "        d14_n = d4 + d14_1\n",
    "        d3 = self.deconv4(d14_n)\n",
    "        d3 = torch.cat((c3, d3), dim=1)\n",
    "        d13_1 = torch.empty_like(d3).normal_(mean=1.0,std=0.1)\n",
    "        d13_n = d3 + d13_1\n",
    "        d2 = self.deconv3(d13_n)\n",
    "        d2 = torch.cat((c2, d2), dim=1)\n",
    "        d12_1 = torch.empty_like(d2).normal_(mean=1.0,std=0.1)\n",
    "        d12_n = d2 + d12_1\n",
    "        d1 = self.deconv2(d12_n)\n",
    "        d1 = torch.add(d1,d1_0)\n",
    "        d1 = torch.cat((c1, d1), dim=1)\n",
    "        d11_1 = torch.empty_like(d1).normal_(mean=1.0,std=0.1)\n",
    "        d11_n = d1 + d11_1\n",
    "        outHR = self.deconv1(d11_n)\n",
    "#         output = torch.add(outLR,outHR)\n",
    "#         d1 = torch.cat((c1, d1), dim=1)\n",
    "#         outHR = self.deconv1(d1)\n",
    "\n",
    "\n",
    "#         return outLR, outHR\n",
    "        return upx,outLR, outHR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Implementation of Pix2Pix')\n",
    "\n",
    "# Task\n",
    "parser.add_argument('--dataroot', required=True, help='path to images (should have subfolders train, val, etc)')\n",
    "parser.add_argument('--which_direction', type=str, default='AtoB', help='AtoB or BtoA')\n",
    "\n",
    "# Options\n",
    "parser.add_argument('--no_resize_or_crop', action='store_true', help='scaling and cropping of images at load time [resize_and_crop|crop|scale_width|scale_width_and_crop]')\n",
    "parser.add_argument('--no_flip', action='store_true', help='if specified, do not flip the images for data augmentation')\n",
    "parser.add_argument('--num_epochs', type=int, default=100)\n",
    "parser.add_argument('--batchSize', type=int, default=1, help='test Batch size')\n",
    "\n",
    "# misc\n",
    "parser.add_argument('--model_path', type=str, default='./models')\n",
    "parser.add_argument('--sample_path', type=str, default='./test_results')\n",
    "parser.add_argument('--results_txt', type=str, default='./test_MSE_PSNR_SSIM.txt')\n",
    "\n",
    "##### Helper Functions for Data Loading & Pre-processing\n",
    "IMG_EXTENSIONS = [\n",
    "    '.jpg', '.JPG', '.jpeg', '.JPEG',\n",
    "    '.png', '.PNG', '.ppm', '.PPM', '.bmp', '.BMP',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Helper Functions for Data Loading & Pre-processingclass ImageFolder(data.Dataset):\n",
    "class ImageFolder(data.Dataset):\n",
    "    def __init__(self, opt):\n",
    "        # os.listdir function gives all lists of directory\n",
    "        self.root = opt.dataroot\n",
    "        self.no_resize_or_crop = opt.no_resize_or_crop\n",
    "        self.no_flip = opt.no_flip\n",
    "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))])\n",
    "        self.transformM = transforms.Compose([transforms.ToTensor()])\n",
    "        #=====================================================================================#\n",
    "        self.dir_A = os.path.join(opt.dataroot,'valx8')\n",
    "        self.Aimg_paths = list(map(lambda x:os.path.join(self.dir_A,x),os.listdir(self.dir_A)))\n",
    "        #=====================================================================================#\n",
    "#         self.dir_AB = os.path.join(opt.dataroot, 'train')\n",
    "#         self.image_paths = list(map(lambda x: os.path.join(self.dir_AB, x), os.listdir(self.dir_AB)))\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        #=====================================================================================#\n",
    "        # A : 32x32 (blur + LR)\n",
    "        # B : 256x256 (LR)\n",
    "        # C : 256x256 (GT)\n",
    "        # D : 256x256 (fmask)\n",
    "        A_path = self.Aimg_paths[index]\n",
    "        trn = A_path.find('valx8')\n",
    "        endn = len(A_path)\n",
    "        C_path = A_path[:trn]+'val_GT'+A_path[trn+5:endn-4]+'.jpg'\n",
    "#         B_path = A_path[:trn]+'GT'+A_path[trn+5:endn-4]+'_mask.jpg'\n",
    "#         print(A_path, C_path)\n",
    "        A = Image.open(A_path).convert('RGB')\n",
    "        C = Image.open(C_path).convert('RGB')\n",
    "#         A = A.resize((256,256),Image.BICUBIC)\n",
    "        B = A.resize((256,256),Image.BICUBIC)\n",
    "        C = C.resize((256,256),Image.BICUBIC)\n",
    "#         B = (C.resize((32,32),Image.BICUBIC)).resize((256,256),Image.BICUBIC)\n",
    "#         C = C.resize((256,256),Image.BICUBIC)\n",
    "#         D = D.resize((256,256),Image.BICUBIC)\n",
    "#         D = D.resize((256,256),Image.BICUBIC)\n",
    "#         D = torch.zeros(256,256)\n",
    "#         D = TTF.to_pil_image(D)\n",
    "        A = self.transform(A)\n",
    "        B = self.transform(B)\n",
    "        C = self.transform(C)\n",
    "#             A = A[:,:32,:32]\n",
    "        A = A[:,:32,:32]\n",
    "        B = B[:,:256,:256]\n",
    "        C = C[:,:256,:256]\n",
    "\n",
    "        return {'A':A,'B':B, 'C':C,'fname':A_path[trn+6:endn-4]}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.Aimg_paths)\n",
    "\n",
    "##### Helper Function for GPU Training\n",
    "def to_variable(x):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return Variable(x)\n",
    "\n",
    "##### Helper Function for Math\n",
    "def denorm(x):\n",
    "    out = (x+1)/2\n",
    "    return out.clamp(0,1)\n",
    "\n",
    "##### Helper Functions for GAN Loss (4D Loss Comparison)\n",
    "def GAN_Loss(input, target, criterion):\n",
    "    if target == True:\n",
    "        tmp_tensor = torch.FloatTensor(input.size()).fill_(1.0)\n",
    "        labels = Variable(tmp_tensor, requires_grad=False)\n",
    "    else:\n",
    "        tmp_tensor = torch.FloatTensor(input.size()).fill_(0.0)\n",
    "        labels = Variable(tmp_tensor, requires_grad=False)\n",
    "        \n",
    "    if torch.cuda.is_available():\n",
    "        labels = labels.cuda()\n",
    "        \n",
    "    return criterion(input, labels)\n",
    "##### Helper Function for Math\n",
    "def denorm(x):\n",
    "    out = (x + 1) / 2\n",
    "    return out.clamp(0, 1)\n",
    "\n",
    "def to_numpy(x):\n",
    "    x = x.cpu()\n",
    "    x = ((x.detach().numpy()+1)/2)\n",
    "    x = np.transpose(x,(1,2,0))\n",
    "    return x\n",
    "\n",
    "def mse(x, y):\n",
    "    return np.linalg.norm(x - y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-settings\n",
    "cudnn.benchmark = True\n",
    "global args\n",
    "args = parser.parse_args(['--dataroot','./datasets/face_SRnDeblur','--which_direction','AtoB',\n",
    "                          '--num_epochs','551','--batchSize','16','--no_resize_or_crop',\n",
    "                          '--model_path','./1031_final_withNevery/models',\n",
    "                          '--sample_path','./1031_final_withNevery/results_e551',\n",
    "                         '--results_txt','./1031_final_withNevery/PSNRSSIM_e551.txt'])\n",
    "# 741 751 761 771 781\n",
    "print(args)\n",
    "\n",
    "dataset = ImageFolder(args)\n",
    "data_loader = data.DataLoader(dataset=dataset,\n",
    "                              batch_size=args.batchSize,\n",
    "                              shuffle=True,\n",
    "                              num_workers=2)\n",
    "\n",
    "if not os.path.exists(args.model_path):\n",
    "    os.makedirs(args.model_path)\n",
    "if not os.path.exists(args.sample_path):\n",
    "    os.makedirs(args.sample_path)\n",
    "\n",
    "    \n",
    "g_path = os.path.join(args.model_path, 'generator-%d.pkl' % (args.num_epochs))\n",
    "print(g_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load pre-trained model\n",
    "generator = Generator(args.batchSize)\n",
    "model_w = torch.load(g_path)\n",
    "model_w1 = dict()\n",
    "for k, v in model_w.items():\n",
    "    nw_name = k[7:]\n",
    "    model_w1[nw_name] = v\n",
    "    \n",
    "generator.load_state_dict(model_w1)\n",
    "# generator.load_state_dict(torch.load(g_path))\n",
    "generator.eval()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    generator = generator.cuda()\n",
    "\n",
    "total_step = len(data_loader) # For Print Log\n",
    "\n",
    "from PIL import Image\n",
    "from skimage import data, img_as_float\n",
    "from skimage.measure import compare_ssim as ssim\n",
    "from skimage.measure import compare_psnr as psnr\n",
    "\n",
    "f = open(args.results_txt,'w')\n",
    "mse_in_all, mse_out_all, psnr_in_all, psnr_out_all, ssim_in_all, ssim_out_all = 0,0,0,0,0,0\n",
    "\n",
    "for i, sample in enumerate(data_loader):\n",
    "\n",
    "    input_A = sample['A']\n",
    "    input_A_Bi = sample['B']\n",
    "    GTHR = sample['C']\n",
    "    testfileN = sample['fname']\n",
    "\n",
    "    in_blurLR = to_variable(input_A)\n",
    "    in_bili = to_variable(input_A_Bi)\n",
    "    upx, fakeLR, fakeHR = generator(in_blurLR)\n",
    "    v_GTHR = to_variable(GTHR)\n",
    "    \n",
    "    # print the log info\n",
    "    print('Validation[%d/%d]' % (i + 1, total_step))\n",
    "    # save the sampled images\n",
    "\n",
    "    in_Ar = upx[:,0:3,:,:]\n",
    "    in_Ar_bi = in_bili[:,0:3,:,:]\n",
    "    fake_Br = fakeHR[:,0:3,:,:]\n",
    "    real_Br = v_GTHR[:,0:3,:,:]\n",
    "    \n",
    "    for k in range(16):\n",
    "        in_Ar_ = img_as_float(to_numpy(in_Ar[k,:,:,:]))\n",
    "        fake_Br_ = img_as_float(to_numpy(fake_Br[k,:,:,:]))\n",
    "        real_Br_ = img_as_float(to_numpy(real_Br[k,:,:,:]))\n",
    "\n",
    "        mse_in = mse(real_Br_,in_Ar_)\n",
    "        mse_out = mse(real_Br_,fake_Br_)\n",
    "        psnr_in = psnr(real_Br_,in_Ar_,data_range=in_Ar_.max()-in_Ar_.min())\n",
    "        psnr_out = psnr(real_Br_,fake_Br_,data_range=fake_Br_.max()-fake_Br_.min())\n",
    "        ssim_in = ssim(real_Br_,in_Ar_,data_range=in_Ar_.max()-in_Ar_.min(),multichannel=True)\n",
    "        ssim_out = ssim(real_Br_,fake_Br_,data_range=fake_Br_.max()-fake_Br_.min(),multichannel=True)\n",
    "\n",
    "        mse_in_all += mse_in\n",
    "        mse_out_all += mse_out\n",
    "        psnr_in_all += psnr_in\n",
    "        psnr_out_all += psnr_out\n",
    "        ssim_in_all += ssim_in\n",
    "        ssim_out_all += ssim_out\n",
    "\n",
    "        f.write('%s.png \\n' % testfileN[k])\n",
    "        f.write('mse_in : %f, psnr_in : %f, ssim_in : %f \\n' % (mse_in, psnr_in, ssim_in))\n",
    "        f.write('mse_out : %f, psnr_out : %f, ssim_out : %f \\n' % (mse_out, psnr_out, ssim_out))\n",
    "        \n",
    "        if not os.path.exists(args.sample_path+'/Generated_1'):\n",
    "            os.makedirs(args.sample_path+'/Generated_1')     \n",
    "        if not os.path.exists(args.sample_path+'/LRGEGT'):\n",
    "            os.makedirs(args.sample_path+'/LRGEGT') \n",
    "            \n",
    "#         torchvision.utils.save_image(denorm(fake_Br[k,:,:,:].data), os.path.join(args.sample_path+'/Generated_1', '%s.png' % testfileN[k]))\n",
    "        torchvision.utils.save_image(denorm(in_Ar_bi[k,:,:,:].data), os.path.join(args.sample_path+'/LR256', '%s.png' % testfileN[k]))\n",
    "\n",
    "#         res = torch.cat((torch.cat((in_Ar_bi[k,:,:,:], fake_Br[k,:,:,:]), dim=2), real_Br[k,:,:,:]), dim=2) \n",
    "#         torchvision.utils.save_image(denorm(res.data), os.path.join(args.sample_path+'/LRGEGT', '%s.png' % testfileN[k]))\n",
    "\n",
    "f.write('Average of MSE PSNR SSIM \\n')\n",
    "f.write('mse_in : %f, psnr_in : %f, ssim_in : %f \\n' % (mse_in_all/1200, psnr_in_all/1200, ssim_in_all/1200))\n",
    "f.write('mse_out : %f, psnr_out : %f, ssim_out : %f \\n' % (mse_out_all/1200, psnr_out_all/1200, ssim_out_all/1200))\n",
    "print('Average of MSE PSNR SSIM \\n')\n",
    "print('mse_in : %f, psnr_in : %f, ssim_in : %f \\n' % (mse_in_all/1200, psnr_in_all/1200, ssim_in_all/1200))\n",
    "print('mse_out : %f, psnr_out : %f, ssim_out : %f \\n' % (mse_out_all/1200, psnr_out_all/1200, ssim_out_all/1200))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.backends import cudnn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, batch_size):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        bn = None\n",
    "        if batch_size == 1:\n",
    "            bn = False # Instance Normalization\n",
    "        else:\n",
    "            bn = True # Batch Normalization\n",
    "\n",
    "        #============================ upscale ============================#\n",
    "        self.upscale8 = nn.Sequential(\n",
    "            # [3x32x32] -> [64x32x32]\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=9, stride=1, padding=4, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # [64x32x32] -> [256x32x32]\n",
    "            nn.Conv2d(in_channels=64, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            # [256x32x32] -> [64x64x64]\n",
    "            nn.PixelShuffle(2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # [64x64x64] -> [256x64x64]\n",
    "            nn.Conv2d(in_channels=64, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            # [256x64x64] -> [64x128x128]\n",
    "            nn.PixelShuffle(2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # [64x128x128] -> [256x128x128]\n",
    "            nn.Conv2d(in_channels=64, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            # [256x128x128] -> [64x256x256]\n",
    "            nn.PixelShuffle(2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),  \n",
    "            # [64x256x256] -> [3x256x256]\n",
    "            nn.Conv2d(in_channels=64, out_channels=3, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        )\n",
    "        #============================ upscale ============================#\n",
    "\n",
    "\n",
    "        # nn.Conv2d(input channel 수, convolution에 의해 생성된 channel 수, kernel size, stride=default 1, padding=default 0)\n",
    "        # [3x256x256] -> [64x128x128]\n",
    "        self.conv1 = nn.Conv2d(3, 64, 4, 2, 1)\n",
    "        # [64x256x256] -> [64x128x128]\n",
    "#         self.conv1 = nn.Conv2d(64, 64, 3, 1, 1)\n",
    "\n",
    "        # -> [128x64x64]\n",
    "        conv2 = [nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            conv2 += [nn.BatchNorm2d(128)]\n",
    "        else:\n",
    "            conv2 += [nn.InstanceNorm2d(128)]\n",
    "        self.conv2 = nn.Sequential(*conv2)\n",
    "\n",
    "        # -> [256x32x32]\n",
    "        conv3 = [nn.LeakyReLU(0.2, inplace=True),\n",
    "                 nn.Conv2d(128, 256, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            conv3 += [nn.BatchNorm2d(256)]\n",
    "        else:\n",
    "            conv3 += [nn.InstanceNorm2d(256)]\n",
    "        self.conv3 = nn.Sequential(*conv3)\n",
    "\n",
    "        # -> [512x16x16]\n",
    "        conv4 = [nn.LeakyReLU(0.2, inplace=True),\n",
    "                 nn.Conv2d(256, 512, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            conv4 += [nn.BatchNorm2d(512)]\n",
    "        else:\n",
    "            conv4 += [nn.InstanceNorm2d(512)]\n",
    "        self.conv4 = nn.Sequential(*conv4)\n",
    "\n",
    "        # -> [512x8x8]\n",
    "        conv5 = [nn.LeakyReLU(0.2, inplace=True),\n",
    "                 nn.Conv2d(512, 512, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            conv5 += [nn.BatchNorm2d(512)]\n",
    "        else:\n",
    "            conv5 += [nn.InstanceNorm2d(512)]\n",
    "        self.conv5 = nn.Sequential(*conv5)\n",
    "\n",
    "        # -> [512x4x4]\n",
    "        conv6 = [nn.LeakyReLU(0.2, inplace=True),\n",
    "                 nn.Conv2d(512, 512, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            conv6 += [nn.BatchNorm2d(512)]\n",
    "        else:\n",
    "            conv6 += [nn.InstanceNorm2d(512)]\n",
    "        self.conv6 = nn.Sequential(*conv6)\n",
    "\n",
    "        # -> [512x2x2]\n",
    "        conv7 = [nn.LeakyReLU(0.2, inplace=True),\n",
    "                 nn.Conv2d(512, 512, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            conv7 += [nn.BatchNorm2d(512)]\n",
    "        else:\n",
    "            conv7 += [nn.InstanceNorm2d(512)]\n",
    "        self.conv7 = nn.Sequential(*conv7)\n",
    "\n",
    "        # -> [512x1x1]\n",
    "        conv8 = [nn.LeakyReLU(0.2, inplace=True),\n",
    "                 nn.Conv2d(512, 512, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            conv8 += [nn.BatchNorm2d(512)]\n",
    "        else:\n",
    "            conv8 += [nn.InstanceNorm2d(512)]\n",
    "        self.conv8 = nn.Sequential(*conv8)\n",
    "\n",
    "        # -> [512x2x2]\n",
    "        deconv8 = [nn.ReLU(),\n",
    "                   nn.ConvTranspose2d(512, 512, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            deconv8 += [nn.BatchNorm2d(512), nn.Dropout(0.5)]\n",
    "        else:\n",
    "            deconv8 += [nn.InstanceNorm2d(512), nn.Dropout(0.5)]\n",
    "        self.deconv8 = nn.Sequential(*deconv8)\n",
    "\n",
    "        # [(512+512)x2x2] -> [512x4x4]\n",
    "        deconv7 = [nn.ReLU(),\n",
    "                   nn.ConvTranspose2d(512 * 2, 512, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            deconv7 += [nn.BatchNorm2d(512), nn.Dropout(0.5)]\n",
    "        else:\n",
    "            deconv7 += [nn.InstanceNorm2d(512), nn.Dropout(0.5)]\n",
    "        self.deconv7 = nn.Sequential(*deconv7)\n",
    "\n",
    "        # [(512+512)x4x4] -> [512x8x8]\n",
    "        deconv6 = [nn.ReLU(),\n",
    "                   nn.ConvTranspose2d(512 * 2, 512, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            deconv6 += [nn.BatchNorm2d(512), nn.Dropout(0.5)]\n",
    "        else:\n",
    "            deconv6 += [nn.InstanceNorm2d(512), nn.Dropout(0.5)]\n",
    "        self.deconv6 = nn.Sequential(*deconv6)\n",
    "\n",
    "        # [(512+512)x8x8] -> [512x16x16]\n",
    "        deconv5 = [nn.ReLU(),\n",
    "                   nn.ConvTranspose2d(512 * 2, 512, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            deconv5 += [nn.BatchNorm2d(512)]\n",
    "        else:\n",
    "            deconv5 += [nn.InstanceNorm2d(512)]\n",
    "        self.deconv5 = nn.Sequential(*deconv5)\n",
    "\n",
    "        # [(512+512)x16x16] -> [256x32x32]\n",
    "        deconv4 = [nn.ReLU(),\n",
    "                   nn.ConvTranspose2d(512 * 2, 256, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            deconv4 += [nn.BatchNorm2d(256)]\n",
    "        else:\n",
    "            deconv4 += [nn.InstanceNorm2d(256)]\n",
    "        self.deconv4 = nn.Sequential(*deconv4)\n",
    "        \n",
    "        # [(512+512)x16x16] -> [256x32x32]\n",
    "        deconv4_0 = [nn.ReLU(),\n",
    "                   nn.ConvTranspose2d(512 * 1, 256, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            deconv4_0 += [nn.BatchNorm2d(256)]\n",
    "        else:\n",
    "            deconv4_0 += [nn.InstanceNorm2d(256)]\n",
    "        self.deconv4_0 = nn.Sequential(*deconv4_0)        \n",
    "\n",
    "        # [(256+256)x32x32] -> [128x64x64]\n",
    "        deconv3 = [nn.ReLU(),\n",
    "                   nn.ConvTranspose2d(256 * 2, 128, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            deconv3 += [nn.BatchNorm2d(128)]\n",
    "        else:\n",
    "            deconv3 += [nn.InstanceNorm2d(128)]\n",
    "        self.deconv3 = nn.Sequential(*deconv3)\n",
    "\n",
    "        # [(256+256)x32x32] -> [128x64x64]\n",
    "        deconv3_0 = [nn.ReLU(),\n",
    "                   nn.ConvTranspose2d(256 * 2, 128, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            deconv3_0 += [nn.BatchNorm2d(128)]\n",
    "        else:\n",
    "            deconv3_0 += [nn.InstanceNorm2d(128)]\n",
    "        self.deconv3_0 = nn.Sequential(*deconv3_0)\n",
    "        \n",
    "        # [(128+128)x64x64] -> [64x128x128]\n",
    "        deconv2 = [nn.ReLU(),\n",
    "                   nn.ConvTranspose2d(128 * 2, 64, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            deconv2 += [nn.BatchNorm2d(64)]\n",
    "        else:\n",
    "            deconv2 += [nn.InstanceNorm2d(64)]\n",
    "        self.deconv2 = nn.Sequential(*deconv2)\n",
    "        \n",
    "        # [(128+128)x64x64] -> [64x128x128]\n",
    "        deconv2_0 = [nn.ReLU(),\n",
    "                   nn.ConvTranspose2d(128 * 2, 64, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            deconv2_0 += [nn.BatchNorm2d(64)]\n",
    "        else:\n",
    "            deconv2_0 += [nn.InstanceNorm2d(64)]\n",
    "        self.deconv2_0 = nn.Sequential(*deconv2_0)\n",
    "\n",
    "        # [(64+64)x128x128] -> [3x256x256]\n",
    "        self.deconv1 = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64 * 2, 3, 4, 2, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        # [(64+64)x128x128] -> [3x256x256]\n",
    "        self.deconv1_0 = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64 * 2, 3, 4, 2, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # NCHW = H*W\n",
    "        \n",
    "        noise = torch.empty_like(x).normal_(mean=1.0,std=0.1)\n",
    "        inN = x + noise\n",
    "        upx = self.upscale8(inN)\n",
    "        \n",
    "        c1 = self.conv1(upx)\n",
    "        c1_1 = torch.empty_like(c1).normal_(mean=1.0,std=0.1)\n",
    "        c1_n = c1 + c1_1\n",
    "        c2 = self.conv2(c1_n)\n",
    "        c2_1 = torch.empty_like(c2).normal_(mean=1.0,std=0.1)\n",
    "        c2_n = c2 + c2_1\n",
    "        c3 = self.conv3(c2_n)\n",
    "        c3_1 = torch.empty_like(c3).normal_(mean=1.0,std=0.1)\n",
    "        c3_n = c3 + c3_1\n",
    "        c4 = self.conv4(c3_n)\n",
    "        c4_1 = torch.empty_like(c4).normal_(mean=1.0,std=0.1)\n",
    "        c4_n = c4 + c4_1\n",
    "        c5 = self.conv5(c4_n)\n",
    "        c5_1 = torch.empty_like(c5).normal_(mean=1.0,std=0.1)\n",
    "        c5_n = c5 + c5_1\n",
    "        c6 = self.conv6(c5_n)\n",
    "        c6_1 = torch.empty_like(c6).normal_(mean=1.0,std=0.1)\n",
    "        c6_n = c6 + c6_1\n",
    "        c7 = self.conv7(c6_n)\n",
    "        c7_1 = torch.empty_like(c7).normal_(mean=1.0,std=0.1)\n",
    "        c7_n = c7 + c7_1\n",
    "        c8 = self.conv8(c7_n)\n",
    "        c8_1 = torch.empty_like(c8).normal_(mean=1.0,std=0.1)\n",
    "        c8_n = c8 + c8_1\n",
    "        \n",
    "        d3_0 = self.deconv4_0(c4_n)\n",
    "        d3_0 = torch.cat((c3,d3_0), dim=1)\n",
    "        d3_1 = torch.empty_like(d3_0).normal_(mean=1.0,std=0.1)\n",
    "        d3_n = d3_0 + d3_1\n",
    "        d2_0 = self.deconv3_0(d3_n)\n",
    "        d2_0 = torch.cat((c2,d2_0), dim=1)\n",
    "        d2_1 = torch.empty_like(d2_0).normal_(mean=1.0,std=0.1)\n",
    "        d2_n = d2_0 + d2_1\n",
    "        d1_0 = self.deconv2_0(d2_n)\n",
    "        d1_00 = torch.cat((c1,d1_0), dim=1)    \n",
    "        d1_1 = torch.empty_like(d1_00).normal_(mean=1.0,std=0.1)\n",
    "        d1_n = d1_00 + d1_1\n",
    "        outLR = self.deconv1_0(d1_n)\n",
    "        \n",
    "        d7 = self.deconv8(c8_n)\n",
    "        d7 = torch.cat((c7, d7), dim=1)\n",
    "        d17_1 = torch.empty_like(d7).normal_(mean=1.0,std=0.1)\n",
    "        d17_n = d7 + d17_1\n",
    "        d6 = self.deconv7(d17_n)\n",
    "        d6 = torch.cat((c6, d6), dim=1)\n",
    "        d16_1 = torch.empty_like(d6).normal_(mean=1.0,std=0.1)\n",
    "        d16_n = d6 + d16_1\n",
    "        d5 = self.deconv6(d16_n)\n",
    "        d5 = torch.cat((c5, d5), dim=1)\n",
    "        d15_1 = torch.empty_like(d5).normal_(mean=1.0,std=0.1)\n",
    "        d15_n = d5 + d15_1\n",
    "        d4 = self.deconv5(d15_n)\n",
    "        d4 = torch.cat((c4, d4), dim=1)\n",
    "        d14_1 = torch.empty_like(d4).normal_(mean=1.0,std=0.1)\n",
    "        d14_n = d4 + d14_1\n",
    "        d3 = self.deconv4(d14_n)\n",
    "        d3 = torch.cat((c3, d3), dim=1)\n",
    "        d13_1 = torch.empty_like(d3).normal_(mean=1.0,std=0.1)\n",
    "        d13_n = d3 + d13_1\n",
    "        d2 = self.deconv3(d13_n)\n",
    "        d2 = torch.cat((c2, d2), dim=1)\n",
    "        d12_1 = torch.empty_like(d2).normal_(mean=1.0,std=0.1)\n",
    "        d12_n = d2 + d12_1\n",
    "        d1 = self.deconv2(d12_n)\n",
    "        d1 = torch.add(d1,d1_0)\n",
    "        d1 = torch.cat((c1, d1), dim=1)\n",
    "        d11_1 = torch.empty_like(d1).normal_(mean=1.0,std=0.1)\n",
    "        d11_n = d1 + d11_1\n",
    "        outHR = self.deconv1(d11_n)\n",
    "#         output = torch.add(outLR,outHR)\n",
    "#         d1 = torch.cat((c1, d1), dim=1)\n",
    "#         outHR = self.deconv1(d1)\n",
    "\n",
    "\n",
    "#         return outLR, outHR\n",
    "        return upx,outLR, outHR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Implementation of Pix2Pix')\n",
    "\n",
    "# Task\n",
    "parser.add_argument('--dataroot', required=True, help='path to images (should have subfolders train, val, etc)')\n",
    "parser.add_argument('--which_direction', type=str, default='AtoB', help='AtoB or BtoA')\n",
    "\n",
    "# Options\n",
    "parser.add_argument('--no_resize_or_crop', action='store_true', help='scaling and cropping of images at load time [resize_and_crop|crop|scale_width|scale_width_and_crop]')\n",
    "parser.add_argument('--no_flip', action='store_true', help='if specified, do not flip the images for data augmentation')\n",
    "parser.add_argument('--num_epochs', type=int, default=100)\n",
    "parser.add_argument('--batchSize', type=int, default=1, help='test Batch size')\n",
    "\n",
    "# misc\n",
    "parser.add_argument('--model_path', type=str, default='./models')\n",
    "parser.add_argument('--sample_path', type=str, default='./test_results')\n",
    "parser.add_argument('--results_txt', type=str, default='./test_MSE_PSNR_SSIM.txt')\n",
    "\n",
    "##### Helper Functions for Data Loading & Pre-processing\n",
    "IMG_EXTENSIONS = [\n",
    "    '.jpg', '.JPG', '.jpeg', '.JPEG',\n",
    "    '.png', '.PNG', '.ppm', '.PPM', '.bmp', '.BMP',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Helper Functions for Data Loading & Pre-processingclass ImageFolder(data.Dataset):\n",
    "class ImageFolder(data.Dataset):\n",
    "    def __init__(self, opt):\n",
    "        # os.listdir function gives all lists of directory\n",
    "        self.root = opt.dataroot\n",
    "        self.no_resize_or_crop = opt.no_resize_or_crop\n",
    "        self.no_flip = opt.no_flip\n",
    "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))])\n",
    "        self.transformM = transforms.Compose([transforms.ToTensor()])\n",
    "        #=====================================================================================#\n",
    "        self.dir_A = os.path.join(opt.dataroot,'val_wmine')\n",
    "        self.Aimg_paths = list(map(lambda x:os.path.join(self.dir_A,x),os.listdir(self.dir_A)))\n",
    "        #=====================================================================================#\n",
    "#         self.dir_AB = os.path.join(opt.dataroot, 'train')\n",
    "#         self.image_paths = list(map(lambda x: os.path.join(self.dir_AB, x), os.listdir(self.dir_AB)))\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        #=====================================================================================#\n",
    "        # A : 32x32 (blur + LR)\n",
    "        # B : 256x256 (LR)\n",
    "        # C : 256x256 (GT)\n",
    "        # D : 256x256 (fmask)\n",
    "        A_path = self.Aimg_paths[index]\n",
    "        trn = A_path.find('val_wmine')\n",
    "        endn = len(A_path)\n",
    "        A = Image.open(A_path).convert('RGB')\n",
    "#         A = A.resize((16,16),Image.BICUBIC)\n",
    "        A = A.resize((32,32),Image.BICUBIC)\n",
    "        B = A.resize((256,256),Image.BICUBIC)\n",
    "        A = self.transform(A)\n",
    "        B = self.transform(B)\n",
    "        A = A[:,:32,:32]\n",
    "        B = B[:,:256,:256]\n",
    "\n",
    "        return {'A':A,'B':B, 'fname':A_path[trn+10:endn-4]}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.Aimg_paths)\n",
    "\n",
    "##### Helper Function for GPU Training\n",
    "def to_variable(x):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return Variable(x)\n",
    "\n",
    "##### Helper Function for Math\n",
    "def denorm(x):\n",
    "    out = (x+1)/2\n",
    "    return out.clamp(0,1)\n",
    "\n",
    "##### Helper Functions for GAN Loss (4D Loss Comparison)\n",
    "def GAN_Loss(input, target, criterion):\n",
    "    if target == True:\n",
    "        tmp_tensor = torch.FloatTensor(input.size()).fill_(1.0)\n",
    "        labels = Variable(tmp_tensor, requires_grad=False)\n",
    "    else:\n",
    "        tmp_tensor = torch.FloatTensor(input.size()).fill_(0.0)\n",
    "        labels = Variable(tmp_tensor, requires_grad=False)\n",
    "        \n",
    "    if torch.cuda.is_available():\n",
    "        labels = labels.cuda()\n",
    "        \n",
    "    return criterion(input, labels)\n",
    "##### Helper Function for Math\n",
    "def denorm(x):\n",
    "    out = (x + 1) / 2\n",
    "    return out.clamp(0, 1)\n",
    "\n",
    "def to_numpy(x):\n",
    "    x = x.cpu()\n",
    "    x = ((x.detach().numpy()+1)/2)\n",
    "    x = np.transpose(x,(1,2,0))\n",
    "    return x\n",
    "\n",
    "def mse(x, y):\n",
    "    return np.linalg.norm(x - y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batchSize=16, dataroot='./datasets/face_SRnDeblur', model_path='./1031_final_withNevery/models', no_flip=False, no_resize_or_crop=True, num_epochs=551, results_txt='./1031_final_withNevery/PSNRSSIM_e551.txt', sample_path='./1031_final_withNevery/valmine551', which_direction='AtoB')\n",
      "./1031_final_withNevery/models/generator-551.pkl\n"
     ]
    }
   ],
   "source": [
    "# Pre-settings\n",
    "cudnn.benchmark = True\n",
    "global args\n",
    "args = parser.parse_args(['--dataroot','./datasets/face_SRnDeblur','--which_direction','AtoB',\n",
    "                          '--num_epochs','551','--batchSize','16','--no_resize_or_crop',\n",
    "                          '--model_path','./1031_final_withNevery/models',\n",
    "                          '--sample_path','./1031_final_withNevery/valmine551',\n",
    "                         '--results_txt','./1031_final_withNevery/PSNRSSIM_e551.txt'])\n",
    "\n",
    "# 741 751 761 771 781\n",
    "print(args)\n",
    "\n",
    "dataset = ImageFolder(args)\n",
    "data_loader = data.DataLoader(dataset=dataset,\n",
    "                              batch_size=args.batchSize,\n",
    "                              shuffle=True,\n",
    "                              num_workers=2)\n",
    "\n",
    "if not os.path.exists(args.model_path):\n",
    "    os.makedirs(args.model_path)\n",
    "if not os.path.exists(args.sample_path):\n",
    "    os.makedirs(args.sample_path)\n",
    "\n",
    "g_path = os.path.join(args.model_path, 'generator-%d.pkl' % (args.num_epochs))\n",
    "print(g_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation[1/2]\n",
      "Validation[2/2]\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model\n",
    "generator = Generator(args.batchSize)\n",
    "model_w = torch.load(g_path)\n",
    "model_w1 = dict()\n",
    "for k, v in model_w.items():\n",
    "    nw_name = k[7:]\n",
    "    model_w1[nw_name] = v\n",
    "    \n",
    "generator.load_state_dict(model_w1)\n",
    "# generator.load_state_dict(torch.load(g_path))\n",
    "generator.eval()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    generator = generator.cuda()\n",
    "\n",
    "total_step = len(data_loader) # For Print Log\n",
    "\n",
    "for i, sample in enumerate(data_loader):\n",
    "\n",
    "    input_A = sample['A']\n",
    "    input_A_Bi = sample['B']\n",
    "    testfileN = sample['fname']\n",
    "\n",
    "    in_blurLR = to_variable(input_A)\n",
    "    in_bili = to_variable(input_A_Bi)\n",
    "    upx, fakeLR, fakeHR = generator(in_blurLR)\n",
    "    \n",
    "    # print the log info\n",
    "    print('Validation[%d/%d]' % (i + 1, total_step))\n",
    "    # save the sampled images\n",
    "\n",
    "    in_Ar = upx[:,0:3,:,:]\n",
    "    in_Ar_bi = in_bili[:,0:3,:,:]\n",
    "    fake_Br = fakeHR[:,0:3,:,:]\n",
    "    \n",
    "    for k in range(16):\n",
    "\n",
    "        if not os.path.exists(args.sample_path+'/Generated'):\n",
    "            os.makedirs(args.sample_path+'/Generated')  \n",
    "            \n",
    "        torchvision.utils.save_image(denorm(in_bili[k,:,:,:].data), os.path.join(args.sample_path+'/Generated/input', '%s_input.png' % testfileN[k]))\n",
    "        torchvision.utils.save_image(denorm(fake_Br[k,:,:,:].data), os.path.join(args.sample_path+'/Generated', '%s.png' % testfileN[k]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(args.sample_path+'/Generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
