{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SRnDeblur_joint 1001 test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.backends import cudnn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, batch_size):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        bn = None\n",
    "        if batch_size == 1:\n",
    "            bn = False # Instance Normalization\n",
    "        else:\n",
    "            bn = True # Batch Normalization\n",
    "\n",
    "        #============================ upscale ============================#\n",
    "        self.upscale8 = nn.Sequential(\n",
    "            # [3x32x32] -> [64x32x32]\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=9, stride=1, padding=4, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # [64x32x32] -> [256x32x32]\n",
    "            nn.Conv2d(in_channels=64, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            # [256x32x32] -> [64x64x64]\n",
    "            nn.PixelShuffle(2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # [64x64x64] -> [256x64x64]\n",
    "            nn.Conv2d(in_channels=64, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            # [256x64x64] -> [64x128x128]\n",
    "            nn.PixelShuffle(2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # [64x128x128] -> [256x128x128]\n",
    "            nn.Conv2d(in_channels=64, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            # [256x128x128] -> [64x256x256]\n",
    "            nn.PixelShuffle(2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),  \n",
    "            # [64x256x256] -> [3x256x256]\n",
    "            nn.Conv2d(in_channels=64, out_channels=3, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        )\n",
    "        #============================ upscale ============================#\n",
    "\n",
    "\n",
    "        # nn.Conv2d(input channel 수, convolution에 의해 생성된 channel 수, kernel size, stride=default 1, padding=default 0)\n",
    "        # [3x256x256] -> [64x128x128]\n",
    "        self.conv1 = nn.Conv2d(3, 64, 4, 2, 1)\n",
    "        # [64x256x256] -> [64x128x128]\n",
    "#         self.conv1 = nn.Conv2d(64, 64, 3, 1, 1)\n",
    "\n",
    "        # -> [128x64x64]\n",
    "        conv2 = [nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            conv2 += [nn.BatchNorm2d(128)]\n",
    "        else:\n",
    "            conv2 += [nn.InstanceNorm2d(128)]\n",
    "        self.conv2 = nn.Sequential(*conv2)\n",
    "\n",
    "        # -> [256x32x32]\n",
    "        conv3 = [nn.LeakyReLU(0.2, inplace=True),\n",
    "                 nn.Conv2d(128, 256, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            conv3 += [nn.BatchNorm2d(256)]\n",
    "        else:\n",
    "            conv3 += [nn.InstanceNorm2d(256)]\n",
    "        self.conv3 = nn.Sequential(*conv3)\n",
    "\n",
    "        # -> [512x16x16]\n",
    "        conv4 = [nn.LeakyReLU(0.2, inplace=True),\n",
    "                 nn.Conv2d(256, 512, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            conv4 += [nn.BatchNorm2d(512)]\n",
    "        else:\n",
    "            conv4 += [nn.InstanceNorm2d(512)]\n",
    "        self.conv4 = nn.Sequential(*conv4)\n",
    "\n",
    "        # -> [512x8x8]\n",
    "        conv5 = [nn.LeakyReLU(0.2, inplace=True),\n",
    "                 nn.Conv2d(512, 512, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            conv5 += [nn.BatchNorm2d(512)]\n",
    "        else:\n",
    "            conv5 += [nn.InstanceNorm2d(512)]\n",
    "        self.conv5 = nn.Sequential(*conv5)\n",
    "\n",
    "        # -> [512x4x4]\n",
    "        conv6 = [nn.LeakyReLU(0.2, inplace=True),\n",
    "                 nn.Conv2d(512, 512, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            conv6 += [nn.BatchNorm2d(512)]\n",
    "        else:\n",
    "            conv6 += [nn.InstanceNorm2d(512)]\n",
    "        self.conv6 = nn.Sequential(*conv6)\n",
    "\n",
    "        # -> [512x2x2]\n",
    "        conv7 = [nn.LeakyReLU(0.2, inplace=True),\n",
    "                 nn.Conv2d(512, 512, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            conv7 += [nn.BatchNorm2d(512)]\n",
    "        else:\n",
    "            conv7 += [nn.InstanceNorm2d(512)]\n",
    "        self.conv7 = nn.Sequential(*conv7)\n",
    "\n",
    "        # -> [512x1x1]\n",
    "        conv8 = [nn.LeakyReLU(0.2, inplace=True),\n",
    "                 nn.Conv2d(512, 512, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            conv8 += [nn.BatchNorm2d(512)]\n",
    "        else:\n",
    "            conv8 += [nn.InstanceNorm2d(512)]\n",
    "        self.conv8 = nn.Sequential(*conv8)\n",
    "\n",
    "        # -> [512x2x2]\n",
    "        deconv8 = [nn.ReLU(),\n",
    "                   nn.ConvTranspose2d(512, 512, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            deconv8 += [nn.BatchNorm2d(512), nn.Dropout(0.5)]\n",
    "        else:\n",
    "            deconv8 += [nn.InstanceNorm2d(512), nn.Dropout(0.5)]\n",
    "        self.deconv8 = nn.Sequential(*deconv8)\n",
    "\n",
    "        # [(512+512)x2x2] -> [512x4x4]\n",
    "        deconv7 = [nn.ReLU(),\n",
    "                   nn.ConvTranspose2d(512 * 2, 512, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            deconv7 += [nn.BatchNorm2d(512), nn.Dropout(0.5)]\n",
    "        else:\n",
    "            deconv7 += [nn.InstanceNorm2d(512), nn.Dropout(0.5)]\n",
    "        self.deconv7 = nn.Sequential(*deconv7)\n",
    "\n",
    "        # [(512+512)x4x4] -> [512x8x8]\n",
    "        deconv6 = [nn.ReLU(),\n",
    "                   nn.ConvTranspose2d(512 * 2, 512, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            deconv6 += [nn.BatchNorm2d(512), nn.Dropout(0.5)]\n",
    "        else:\n",
    "            deconv6 += [nn.InstanceNorm2d(512), nn.Dropout(0.5)]\n",
    "        self.deconv6 = nn.Sequential(*deconv6)\n",
    "\n",
    "        # [(512+512)x8x8] -> [512x16x16]\n",
    "        deconv5 = [nn.ReLU(),\n",
    "                   nn.ConvTranspose2d(512 * 2, 512, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            deconv5 += [nn.BatchNorm2d(512)]\n",
    "        else:\n",
    "            deconv5 += [nn.InstanceNorm2d(512)]\n",
    "        self.deconv5 = nn.Sequential(*deconv5)\n",
    "\n",
    "        # [(512+512)x16x16] -> [256x32x32]\n",
    "        deconv4 = [nn.ReLU(),\n",
    "                   nn.ConvTranspose2d(512 * 2, 256, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            deconv4 += [nn.BatchNorm2d(256)]\n",
    "        else:\n",
    "            deconv4 += [nn.InstanceNorm2d(256)]\n",
    "        self.deconv4 = nn.Sequential(*deconv4)\n",
    "        \n",
    "        # [(512+512)x16x16] -> [256x32x32]\n",
    "        deconv4_0 = [nn.ReLU(),\n",
    "                   nn.ConvTranspose2d(512 * 1, 256, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            deconv4_0 += [nn.BatchNorm2d(256)]\n",
    "        else:\n",
    "            deconv4_0 += [nn.InstanceNorm2d(256)]\n",
    "        self.deconv4_0 = nn.Sequential(*deconv4_0)        \n",
    "\n",
    "        # [(256+256)x32x32] -> [128x64x64]\n",
    "        deconv3 = [nn.ReLU(),\n",
    "                   nn.ConvTranspose2d(256 * 2, 128, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            deconv3 += [nn.BatchNorm2d(128)]\n",
    "        else:\n",
    "            deconv3 += [nn.InstanceNorm2d(128)]\n",
    "        self.deconv3 = nn.Sequential(*deconv3)\n",
    "\n",
    "        # [(256+256)x32x32] -> [128x64x64]\n",
    "        deconv3_0 = [nn.ReLU(),\n",
    "                   nn.ConvTranspose2d(256 * 2, 128, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            deconv3_0 += [nn.BatchNorm2d(128)]\n",
    "        else:\n",
    "            deconv3_0 += [nn.InstanceNorm2d(128)]\n",
    "        self.deconv3_0 = nn.Sequential(*deconv3_0)\n",
    "        \n",
    "        # [(128+128)x64x64] -> [64x128x128]\n",
    "        deconv2 = [nn.ReLU(),\n",
    "                   nn.ConvTranspose2d(128 * 2, 64, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            deconv2 += [nn.BatchNorm2d(64)]\n",
    "        else:\n",
    "            deconv2 += [nn.InstanceNorm2d(64)]\n",
    "        self.deconv2 = nn.Sequential(*deconv2)\n",
    "        \n",
    "        # [(128+128)x64x64] -> [64x128x128]\n",
    "        deconv2_0 = [nn.ReLU(),\n",
    "                   nn.ConvTranspose2d(128 * 2, 64, 4, 2, 1)]\n",
    "        if bn == True:\n",
    "            deconv2_0 += [nn.BatchNorm2d(64)]\n",
    "        else:\n",
    "            deconv2_0 += [nn.InstanceNorm2d(64)]\n",
    "        self.deconv2_0 = nn.Sequential(*deconv2_0)\n",
    "\n",
    "        # [(64+64)x128x128] -> [3x256x256]\n",
    "        self.deconv1 = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64 * 2, 3, 4, 2, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        # [(64+64)x128x128] -> [3x256x256]\n",
    "        self.deconv1_0 = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64 * 2, 3, 4, 2, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        upx = self.upscale8(x)\n",
    "        c1 = self.conv1(upx)\n",
    "        c2 = self.conv2(c1)\n",
    "        c3 = self.conv3(c2)\n",
    "        c4 = self.conv4(c3)\n",
    "        c5 = self.conv5(c4)\n",
    "        c6 = self.conv6(c5)\n",
    "        c7 = self.conv7(c6)\n",
    "        c8 = self.conv8(c7)\n",
    "        \n",
    "        d3_0 = self.deconv4_0(c4)\n",
    "        d3_0 = torch.cat((c3,d3_0), dim=1)\n",
    "        d2_0 = self.deconv3_0(d3_0)\n",
    "        d2_0 = torch.cat((c2,d2_0), dim=1)\n",
    "        d1_0 = self.deconv2_0(d2_0)\n",
    "        d1_00 = torch.cat((c1,d1_0), dim=1)\n",
    "        outLR = self.deconv1_0(d1_00)\n",
    "        \n",
    "        d7 = self.deconv8(c8)\n",
    "        d7 = torch.cat((c7, d7), dim=1)\n",
    "        d6 = self.deconv7(d7)\n",
    "        d6 = torch.cat((c6, d6), dim=1)\n",
    "        d5 = self.deconv6(d6)\n",
    "        d5 = torch.cat((c5, d5), dim=1)\n",
    "        d4 = self.deconv5(d5)\n",
    "        d4 = torch.cat((c4, d4), dim=1)\n",
    "        d3 = self.deconv4(d4)\n",
    "        d3 = torch.cat((c3, d3), dim=1)\n",
    "        d2 = self.deconv3(d3)\n",
    "        d2 = torch.cat((c2, d2), dim=1)\n",
    "        d1 = self.deconv2(d2)\n",
    "        d1 = torch.add(d1,d1_0)\n",
    "        d1 = torch.cat((c1, d1), dim=1)\n",
    "        outHR = self.deconv1(d1)\n",
    "#         output = torch.add(outLR,outHR)\n",
    "#         d1 = torch.cat((c1, d1), dim=1)\n",
    "#         outHR = self.deconv1(d1)\n",
    "\n",
    "\n",
    "#         return outLR, outHR\n",
    "        return upx,outLR, outHR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Implementation of Pix2Pix')\n",
    "\n",
    "# Task\n",
    "parser.add_argument('--dataroot', required=True, help='path to images (should have subfolders train, val, etc)')\n",
    "parser.add_argument('--which_direction', type=str, default='AtoB', help='AtoB or BtoA')\n",
    "\n",
    "# Options\n",
    "parser.add_argument('--no_resize_or_crop', action='store_true', help='scaling and cropping of images at load time [resize_and_crop|crop|scale_width|scale_width_and_crop]')\n",
    "parser.add_argument('--no_flip', action='store_true', help='if specified, do not flip the images for data augmentation')\n",
    "parser.add_argument('--num_epochs', type=int, default=100)\n",
    "parser.add_argument('--batchSize', type=int, default=1, help='test Batch size')\n",
    "\n",
    "# misc\n",
    "parser.add_argument('--model_path', type=str, default='./models')\n",
    "parser.add_argument('--sample_path', type=str, default='./test_results')\n",
    "parser.add_argument('--results_txt', type=str, default='./test_MSE_PSNR_SSIM.txt')\n",
    "\n",
    "##### Helper Functions for Data Loading & Pre-processing\n",
    "IMG_EXTENSIONS = [\n",
    "    '.jpg', '.JPG', '.jpeg', '.JPEG',\n",
    "    '.png', '.PNG', '.ppm', '.PPM', '.bmp', '.BMP',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Helper Functions for Data Loading & Pre-processingclass ImageFolder(data.Dataset):\n",
    "class ImageFolder(data.Dataset):\n",
    "    def __init__(self, opt):\n",
    "        # os.listdir function gives all lists of directory\n",
    "        self.root = opt.dataroot\n",
    "        self.no_resize_or_crop = opt.no_resize_or_crop\n",
    "        self.no_flip = opt.no_flip\n",
    "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))])\n",
    "        self.transformM = transforms.Compose([transforms.ToTensor()])\n",
    "        #=====================================================================================#\n",
    "        self.dir_A = os.path.join(opt.dataroot,'celeba_val_1000_LR_8x')\n",
    "        self.Aimg_paths = list(map(lambda x:os.path.join(self.dir_A,x),os.listdir(self.dir_A)))\n",
    "        #=====================================================================================#\n",
    "#         self.dir_AB = os.path.join(opt.dataroot, 'train')\n",
    "#         self.image_paths = list(map(lambda x: os.path.join(self.dir_AB, x), os.listdir(self.dir_AB)))\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        #=====================================================================================#\n",
    "        # A : 32x32 (blur + LR)\n",
    "        # B : 256x256 (LR)\n",
    "        # C : 256x256 (GT)\n",
    "        # D : 256x256 (fmask)\n",
    "        A_path = self.Aimg_paths[index]\n",
    "        trn = A_path.find('LR')\n",
    "        endn = len(A_path)\n",
    "        C_path = A_path[:trn]+'HR'+A_path[trn+5:endn-4]+'.jpg'\n",
    "\n",
    "#         B_path = A_path[:trn]+'GT'+A_path[trn+5:endn-4]+'_mask.jpg'\n",
    "#         print(A_path, C_path)\n",
    "        A = Image.open(A_path).convert('RGB')\n",
    "        C = Image.open(C_path).convert('RGB')\n",
    "        B = A\n",
    "        A = C.resize((32,32),Image.BICUBIC)\n",
    "        C = C.resize((256,256),Image.BICUBIC)\n",
    "#         B = (C.resize((32,32),Image.BICUBIC)).resize((256,256),Image.BICUBIC)\n",
    "#         C = C.resize((256,256),Image.BICUBIC)\n",
    "#         D = D.resize((256,256),Image.BICUBIC)\n",
    "#         D = D.resize((256,256),Image.BICUBIC)\n",
    "#         D = torch.zeros(256,256)\n",
    "#         D = TTF.to_pil_image(D)\n",
    "        A = self.transform(A)\n",
    "        B = self.transform(B)\n",
    "        C = self.transform(C)\n",
    "#             A = A[:,:32,:32]\n",
    "        A = A[:,:32,:32]\n",
    "        B = B[:,:256,:256]\n",
    "        C = C[:,:256,:256]\n",
    "\n",
    "        return {'A':A,'B':B, 'C':C,'fname':A_path[trn+6:endn-4]}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.Aimg_paths)\n",
    "\n",
    "##### Helper Function for GPU Training\n",
    "def to_variable(x):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return Variable(x)\n",
    "\n",
    "##### Helper Function for Math\n",
    "def denorm(x):\n",
    "    out = (x+1)/2\n",
    "    return out.clamp(0,1)\n",
    "\n",
    "##### Helper Functions for GAN Loss (4D Loss Comparison)\n",
    "def GAN_Loss(input, target, criterion):\n",
    "    if target == True:\n",
    "        tmp_tensor = torch.FloatTensor(input.size()).fill_(1.0)\n",
    "        labels = Variable(tmp_tensor, requires_grad=False)\n",
    "    else:\n",
    "        tmp_tensor = torch.FloatTensor(input.size()).fill_(0.0)\n",
    "        labels = Variable(tmp_tensor, requires_grad=False)\n",
    "        \n",
    "    if torch.cuda.is_available():\n",
    "        labels = labels.cuda()\n",
    "        \n",
    "    return criterion(input, labels)\n",
    "##### Helper Function for Math\n",
    "def denorm(x):\n",
    "    out = (x + 1) / 2\n",
    "    return out.clamp(0, 1)\n",
    "\n",
    "def to_numpy(x):\n",
    "    x = x.cpu()\n",
    "    x = ((x.detach().numpy()+1)/2)\n",
    "    x = np.transpose(x,(1,2,0))\n",
    "    return x\n",
    "\n",
    "def mse(x, y):\n",
    "    return np.linalg.norm(x - y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batchSize=4, dataroot='./comparison_results', model_path='./1031_final_withNevery/models', no_flip=False, no_resize_or_crop=True, num_epochs=551, results_txt='./1031_final_withNevery/celebA_PSNRSSIM_e551.txt', sample_path='./1031_final_withNevery/celebA_results_e551', which_direction='AtoB')\n",
      "./1031_final_withNevery/models/generator-551.pkl\n"
     ]
    }
   ],
   "source": [
    "# Pre-settings\n",
    "cudnn.benchmark = True\n",
    "global args\n",
    "args = parser.parse_args(['--dataroot','./comparison_results','--which_direction','AtoB',\n",
    "                          '--num_epochs','551','--batchSize','4','--no_resize_or_crop',\n",
    "                          '--model_path','./1031_final_withNevery/models',\n",
    "                          '--sample_path','./1031_final_withNevery/celebA_results_e551',\n",
    "                         '--results_txt','./1031_final_withNevery/celebA_PSNRSSIM_e551.txt'])\n",
    "# 741 751 761 771 781\n",
    "print(args)\n",
    "\n",
    "dataset = ImageFolder(args)\n",
    "data_loader = data.DataLoader(dataset=dataset,\n",
    "                              batch_size=args.batchSize,\n",
    "                              shuffle=True,\n",
    "                              num_workers=2)\n",
    "\n",
    "if not os.path.exists(args.model_path):\n",
    "    os.makedirs(args.model_path)\n",
    "if not os.path.exists(args.sample_path):\n",
    "    os.makedirs(args.sample_path)\n",
    "\n",
    "g_path = os.path.join(args.model_path, 'generator-%d.pkl' % (args.num_epochs))\n",
    "print(g_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation[1/251]\n",
      "Validation[2/251]\n",
      "Validation[3/251]\n",
      "Validation[4/251]\n",
      "Validation[5/251]\n",
      "Validation[6/251]\n",
      "Validation[7/251]\n",
      "Validation[8/251]\n",
      "Validation[9/251]\n",
      "Validation[10/251]\n",
      "Validation[11/251]\n",
      "Validation[12/251]\n",
      "Validation[13/251]\n",
      "Validation[14/251]\n",
      "Validation[15/251]\n",
      "Validation[16/251]\n",
      "Validation[17/251]\n",
      "Validation[18/251]\n",
      "Validation[19/251]\n",
      "Validation[20/251]\n",
      "Validation[21/251]\n",
      "Validation[22/251]\n",
      "Validation[23/251]\n",
      "Validation[24/251]\n",
      "Validation[25/251]\n",
      "Validation[26/251]\n",
      "Validation[27/251]\n",
      "Validation[28/251]\n",
      "Validation[29/251]\n",
      "Validation[30/251]\n",
      "Validation[31/251]\n",
      "Validation[32/251]\n",
      "Validation[33/251]\n",
      "Validation[34/251]\n",
      "Validation[35/251]\n",
      "Validation[36/251]\n",
      "Validation[37/251]\n",
      "Validation[38/251]\n",
      "Validation[39/251]\n",
      "Validation[40/251]\n",
      "Validation[41/251]\n",
      "Validation[42/251]\n",
      "Validation[43/251]\n",
      "Validation[44/251]\n",
      "Validation[45/251]\n",
      "Validation[46/251]\n",
      "Validation[47/251]\n",
      "Validation[48/251]\n",
      "Validation[49/251]\n",
      "Validation[50/251]\n",
      "Validation[51/251]\n",
      "Validation[52/251]\n",
      "Validation[53/251]\n",
      "Validation[54/251]\n",
      "Validation[55/251]\n",
      "Validation[56/251]\n",
      "Validation[57/251]\n",
      "Validation[58/251]\n",
      "Validation[59/251]\n",
      "Validation[60/251]\n",
      "Validation[61/251]\n",
      "Validation[62/251]\n",
      "Validation[63/251]\n",
      "Validation[64/251]\n",
      "Validation[65/251]\n",
      "Validation[66/251]\n",
      "Validation[67/251]\n",
      "Validation[68/251]\n",
      "Validation[69/251]\n",
      "Validation[70/251]\n",
      "Validation[71/251]\n",
      "Validation[72/251]\n",
      "Validation[73/251]\n",
      "Validation[74/251]\n",
      "Validation[75/251]\n",
      "Validation[76/251]\n",
      "Validation[77/251]\n",
      "Validation[78/251]\n",
      "Validation[79/251]\n",
      "Validation[80/251]\n",
      "Validation[81/251]\n",
      "Validation[82/251]\n",
      "Validation[83/251]\n",
      "Validation[84/251]\n",
      "Validation[85/251]\n",
      "Validation[86/251]\n",
      "Validation[87/251]\n",
      "Validation[88/251]\n",
      "Validation[89/251]\n",
      "Validation[90/251]\n",
      "Validation[91/251]\n",
      "Validation[92/251]\n",
      "Validation[93/251]\n",
      "Validation[94/251]\n",
      "Validation[95/251]\n",
      "Validation[96/251]\n",
      "Validation[97/251]\n",
      "Validation[98/251]\n",
      "Validation[99/251]\n",
      "Validation[100/251]\n",
      "Validation[101/251]\n",
      "Validation[102/251]\n",
      "Validation[103/251]\n",
      "Validation[104/251]\n",
      "Validation[105/251]\n",
      "Validation[106/251]\n",
      "Validation[107/251]\n",
      "Validation[108/251]\n",
      "Validation[109/251]\n",
      "Validation[110/251]\n",
      "Validation[111/251]\n",
      "Validation[112/251]\n",
      "Validation[113/251]\n",
      "Validation[114/251]\n",
      "Validation[115/251]\n",
      "Validation[116/251]\n",
      "Validation[117/251]\n",
      "Validation[118/251]\n",
      "Validation[119/251]\n",
      "Validation[120/251]\n",
      "Validation[121/251]\n",
      "Validation[122/251]\n",
      "Validation[123/251]\n",
      "Validation[124/251]\n",
      "Validation[125/251]\n",
      "Validation[126/251]\n",
      "Validation[127/251]\n",
      "Validation[128/251]\n",
      "Validation[129/251]\n",
      "Validation[130/251]\n",
      "Validation[131/251]\n",
      "Validation[132/251]\n",
      "Validation[133/251]\n",
      "Validation[134/251]\n",
      "Validation[135/251]\n",
      "Validation[136/251]\n",
      "Validation[137/251]\n",
      "Validation[138/251]\n",
      "Validation[139/251]\n",
      "Validation[140/251]\n",
      "Validation[141/251]\n",
      "Validation[142/251]\n",
      "Validation[143/251]\n",
      "Validation[144/251]\n",
      "Validation[145/251]\n",
      "Validation[146/251]\n",
      "Validation[147/251]\n",
      "Validation[148/251]\n",
      "Validation[149/251]\n",
      "Validation[150/251]\n",
      "Validation[151/251]\n",
      "Validation[152/251]\n",
      "Validation[153/251]\n",
      "Validation[154/251]\n",
      "Validation[155/251]\n",
      "Validation[156/251]\n",
      "Validation[157/251]\n",
      "Validation[158/251]\n",
      "Validation[159/251]\n",
      "Validation[160/251]\n",
      "Validation[161/251]\n",
      "Validation[162/251]\n",
      "Validation[163/251]\n",
      "Validation[164/251]\n",
      "Validation[165/251]\n",
      "Validation[166/251]\n",
      "Validation[167/251]\n",
      "Validation[168/251]\n",
      "Validation[169/251]\n",
      "Validation[170/251]\n",
      "Validation[171/251]\n",
      "Validation[172/251]\n",
      "Validation[173/251]\n",
      "Validation[174/251]\n",
      "Validation[175/251]\n",
      "Validation[176/251]\n",
      "Validation[177/251]\n",
      "Validation[178/251]\n",
      "Validation[179/251]\n",
      "Validation[180/251]\n",
      "Validation[181/251]\n",
      "Validation[182/251]\n",
      "Validation[183/251]\n",
      "Validation[184/251]\n",
      "Validation[185/251]\n",
      "Validation[186/251]\n",
      "Validation[187/251]\n",
      "Validation[188/251]\n",
      "Validation[189/251]\n",
      "Validation[190/251]\n",
      "Validation[191/251]\n",
      "Validation[192/251]\n",
      "Validation[193/251]\n",
      "Validation[194/251]\n",
      "Validation[195/251]\n",
      "Validation[196/251]\n",
      "Validation[197/251]\n",
      "Validation[198/251]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Traceback (most recent call last):\n  File \"/home/juyun/anaconda3/envs/DL/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 99, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/juyun/anaconda3/envs/DL/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 99, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-4-ae978b21993e>\", line 30, in __getitem__\n    A = Image.open(A_path).convert('RGB')\n  File \"/home/juyun/anaconda3/envs/DL/lib/python3.7/site-packages/PIL/Image.py\", line 2822, in open\n    raise IOError(\"cannot identify image file %r\" % (filename if filename else fp))\nOSError: cannot identify image file './comparison_results/celeba_val_1000_LR_8x/.directory'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-206dce631184>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mmse_in_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse_out_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpsnr_in_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpsnr_out_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mssim_in_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mssim_out_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0minput_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'A'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DL/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    580\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DL/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"KeyError:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Traceback (most recent call last):\n  File \"/home/juyun/anaconda3/envs/DL/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 99, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/juyun/anaconda3/envs/DL/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 99, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-4-ae978b21993e>\", line 30, in __getitem__\n    A = Image.open(A_path).convert('RGB')\n  File \"/home/juyun/anaconda3/envs/DL/lib/python3.7/site-packages/PIL/Image.py\", line 2822, in open\n    raise IOError(\"cannot identify image file %r\" % (filename if filename else fp))\nOSError: cannot identify image file './comparison_results/celeba_val_1000_LR_8x/.directory'\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model\n",
    "generator = Generator(args.batchSize)\n",
    "model_w = torch.load(g_path)\n",
    "model_w1 = dict()\n",
    "for k, v in model_w.items():\n",
    "    nw_name = k[7:]\n",
    "    model_w1[nw_name] = v\n",
    "    \n",
    "generator.load_state_dict(model_w1)\n",
    "# generator.load_state_dict(torch.load(g_path))\n",
    "generator.eval()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    generator = generator.cuda()\n",
    "\n",
    "total_step = len(data_loader) # For Print Log\n",
    "\n",
    "from PIL import Image\n",
    "from skimage import data, img_as_float\n",
    "from skimage.measure import compare_ssim as ssim\n",
    "from skimage.measure import compare_psnr as psnr\n",
    "\n",
    "f = open(args.results_txt,'w')\n",
    "mse_in_all, mse_out_all, psnr_in_all, psnr_out_all, ssim_in_all, ssim_out_all = 0,0,0,0,0,0\n",
    "\n",
    "for i, sample in enumerate(data_loader):\n",
    "\n",
    "    input_A = sample['A']\n",
    "    input_A_Bi = sample['B']\n",
    "    GTHR = sample['C']\n",
    "    testfileN = sample['fname']\n",
    "\n",
    "    in_blurLR = to_variable(input_A)\n",
    "    in_bili = to_variable(input_A_Bi)\n",
    "    upx, fakeLR, fakeHR = generator(in_blurLR)\n",
    "    v_GTHR = to_variable(GTHR)\n",
    "    \n",
    "    # print the log info\n",
    "    print('Validation[%d/%d]' % (i + 1, total_step))\n",
    "    # save the sampled images\n",
    "\n",
    "    in_Ar = upx[:,0:3,:,:]\n",
    "    fake_Br = fakeHR[:,0:3,:,:]\n",
    "    real_Br = v_GTHR[:,0:3,:,:]\n",
    "    \n",
    "    for k in range(args.batchSize):\n",
    "        in_Ar_ = img_as_float(to_numpy(in_Ar[k,:,:,:]))\n",
    "        fake_Br_ = img_as_float(to_numpy(fake_Br[k,:,:,:]))\n",
    "        real_Br_ = img_as_float(to_numpy(real_Br[k,:,:,:]))\n",
    "\n",
    "        mse_in = mse(real_Br_,in_Ar_)\n",
    "        mse_out = mse(real_Br_,fake_Br_)\n",
    "        psnr_in = psnr(real_Br_,in_Ar_,data_range=in_Ar_.max()-in_Ar_.min())\n",
    "        psnr_out = psnr(real_Br_,fake_Br_,data_range=fake_Br_.max()-fake_Br_.min())\n",
    "        ssim_in = ssim(real_Br_,in_Ar_,data_range=in_Ar_.max()-in_Ar_.min(),multichannel=True)\n",
    "        ssim_out = ssim(real_Br_,fake_Br_,data_range=fake_Br_.max()-fake_Br_.min(),multichannel=True)\n",
    "\n",
    "        mse_in_all += mse_in\n",
    "        mse_out_all += mse_out\n",
    "        psnr_in_all += psnr_in\n",
    "        psnr_out_all += psnr_out\n",
    "        ssim_in_all += ssim_in\n",
    "        ssim_out_all += ssim_out\n",
    "\n",
    "        f.write('%s.png \\n' % testfileN[k])\n",
    "        f.write('mse_in : %f, psnr_in : %f, ssim_in : %f \\n' % (mse_in, psnr_in, ssim_in))\n",
    "        f.write('mse_out : %f, psnr_out : %f, ssim_out : %f \\n' % (mse_out, psnr_out, ssim_out))\n",
    "       \n",
    "        if not os.path.exists(args.sample_path+'/Generated_celebA'):\n",
    "            os.makedirs(args.sample_path+'/Generated_celebA') \n",
    "\n",
    "        torchvision.utils.save_image(denorm(fake_Br[k,:,:,:].data), os.path.join(args.sample_path+'/Generated_celebA', '%s.png' % testfileN[k]))\n",
    "    \n",
    "#         res = torch.cat((torch.cat((in_Ar[k,:,:,:], fake_Br[k,:,:,:]), dim=2), real_Br[k,:,:,:]), dim=2)\n",
    "#         torchvision.utils.save_image(denorm(res.data), os.path.join(args.sample_path, '%s.png' % testfileN[k]))\n",
    "\n",
    "f.write('Average of MSE PSNR SSIM \\n')\n",
    "f.write('mse_in : %f, psnr_in : %f, ssim_in : %f \\n' % (mse_in_all/1200, psnr_in_all/1200, ssim_in_all/1200))\n",
    "f.write('mse_out : %f, psnr_out : %f, ssim_out : %f \\n' % (mse_out_all/1200, psnr_out_all/1200, ssim_out_all/1200))\n",
    "print('Average of MSE PSNR SSIM \\n')\n",
    "print('mse_in : %f, psnr_in : %f, ssim_in : %f \\n' % (mse_in_all/1200, psnr_in_all/1200, ssim_in_all/1200))\n",
    "print('mse_out : %f, psnr_out : %f, ssim_out : %f \\n' % (mse_out_all/1200, psnr_out_all/1200, ssim_out_all/1200))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.sample_path+'/Generated_celebA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfileN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
